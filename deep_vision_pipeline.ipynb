{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fa4cdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9f6113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset loader function\n",
    "\n",
    "def load_training_dataset(csv_path, img_dir, transform=None):\n",
    "    \"\"\"\n",
    "    Loads training images and labels from a CSV and image directory,\n",
    "    and returns a PyTorch Dataset object.\n",
    "    \n",
    "    Parameters:\n",
    "        csv_path (str): Path to the labels CSV file.\n",
    "        img_dir (str): Path to the folder containing image files.\n",
    "        transform (torchvision.transforms): Transformations to apply to each image.\n",
    "    \n",
    "    Returns:\n",
    "        torch.utils.data.Dataset: A dataset object to use with DataLoader.\n",
    "    \"\"\"\n",
    "    \n",
    "    class ImageDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, csv_path, img_dir, transform=None):\n",
    "            self.labels_df = pd.read_csv(csv_path)\n",
    "            self.img_dir = img_dir\n",
    "            self.transform = transform\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.labels_df)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            img_name = str(self.labels_df.iloc[idx, 0]) + \".png\"  # Convert to string and add .png if needed\n",
    "            label = int(self.labels_df.iloc[idx, 1])  # Ensure label is an integer\n",
    "            img_path = os.path.join(self.img_dir, img_name)\n",
    "            image = Image.open(img_path).convert(\"RGB\")  # You're using 3 channels\n",
    "\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "\n",
    "            return image, label\n",
    "\n",
    "\n",
    "    return ImageDataset(csv_path, img_dir, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f99552d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset using the function above \n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # for RGB channels\n",
    "])\n",
    "\n",
    "\n",
    "# Paths\n",
    "csv_path = \"data/train/labels_train.csv\"\n",
    "img_dir = \"data/train/\"\n",
    "\n",
    "# Get the dataset\n",
    "train_dataset = load_training_dataset(csv_path, img_dir, transform=transform)\n",
    "\n",
    "# Wrap it in a DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f427d90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN architecture\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNNModel, self).__init__()\n",
    "        \n",
    "        # Convolutional Layer 1: Input 3 channels (RGB), output 16 channels (feature maps), 3x3 kernel\n",
    "        self.conv1 = nn.Conv2d(in_channels=input_channels, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        # Convolutional Layer 2: Input 16 channels, output 32 channels, 3x3 kernel\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Convolutional Layer 3: Input 32 channels, output 64 channels, 3x3 kernel\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Fully connected layer to map to 26 classes\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 512)  # Flattened size: 64 channels * 8x8 spatial size\n",
    "        self.fc2 = nn.Linear(512, num_classes)  # Output 26 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass input through the layers\n",
    "        x = self.pool1(torch.relu(self.conv1(x)))  # ReLU activation after conv1 + pooling\n",
    "        x = self.pool2(torch.relu(self.conv2(x)))  # ReLU activation after conv2 + pooling\n",
    "        x = self.pool3(torch.relu(self.conv3(x)))  # ReLU activation after conv3 + pooling\n",
    "\n",
    "        # Flatten the output for the fully connected layer\n",
    "        x = x.view(-1, 64 * 8 * 8)  # Flatten the tensor to shape (batch_size, 64 * 8 * 8)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = torch.relu(self.fc1(x))  # ReLU activation after fc1\n",
    "        x = self.fc2(x)  # Output layer (no activation function here, since we use CrossEntropyLoss)\n",
    "\n",
    "        return x\n",
    "    \n",
    "# Instantiate your model (e.g., with 26 classes for your problem)\n",
    "model = CNNModel(input_channels=3,num_classes=26)  # Adjust the number of classes as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9464abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "\n",
    "# Let's say 'train_dataset' is your full training dataset object\n",
    "subset_indices = np.random.choice(len(train_dataset), size=500, replace=False)  # choose 500 random samples\n",
    "subset = Subset(train_dataset, subset_indices)\n",
    "\n",
    "# Create a DataLoader for the subset\n",
    "subset_loader = DataLoader(subset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91bdace7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 3.2700\n",
      "Epoch 2/5, Loss: 3.2563\n",
      "Epoch 3/5, Loss: 3.2493\n",
      "Epoch 4/5, Loss: 3.2367\n",
      "Epoch 5/5, Loss: 3.2232\n"
     ]
    }
   ],
   "source": [
    "# Test the model with a subset of the dataset\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()  # For multi-class classification\n",
    "\n",
    "# Define the optimizer (Adam is a popular choice)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # You can adjust the learning rate as needed\n",
    "\n",
    "# Number of epochs you want to train for\n",
    "num_epochs = 5\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Loop over the batches of data from the subset DataLoader\n",
    "    for inputs, labels in subset_loader:\n",
    "        \n",
    "        # Zero the gradients from the previous step\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass: Compute predicted outputs by passing inputs to the model\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass: Compute gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update running loss (for monitoring)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Calculate average loss for this epoch\n",
    "    avg_loss = running_loss / len(subset_loader)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
